{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d14d994-d9e1-4265-a619-e55c6a6168de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import Resize, ToPILImage, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888a81a2-517b-4f8d-bee5-1e2e5a94d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.9\n",
    "image_size = 32\n",
    "p = 0.95\n",
    "threshold_norm = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d27751d-3afd-46f9-a286-6a1850708ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    if(x >= 0):\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe57d0c-85b9-4d0d-a259-5bbba77cb5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10000\n",
      "1000/10000\n",
      "2000/10000\n",
      "3000/10000\n",
      "4000/10000\n",
      "5000/10000\n",
      "6000/10000\n",
      "7000/10000\n",
      "8000/10000\n",
      "9000/10000\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "z = torch.randn((n, 2))\n",
    "\n",
    "for i in range(n):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i}/{n}\")\n",
    "    \n",
    "    z1 = max(min((z[i][0].item()), threshold_norm), -threshold_norm)/threshold_norm\n",
    "    z2 = max(min((z[i][1].item()), threshold_norm), -threshold_norm)/threshold_norm\n",
    "    \n",
    "    x = np.zeros((image_size, image_size))\n",
    "    origin_pos_x = int(image_size/2) - int((1 - sign(z1))/2)\n",
    "    origin_pos_y = int(image_size/2) - int((1 - sign(z2))/2)\n",
    "    if abs(z1) > abs(z2):\n",
    "        for x_pos in range(origin_pos_x, origin_pos_x + round(image_size/2*r*z1), sign(z1)):\n",
    "            y_pos = round(z2/z1*(x_pos - origin_pos_x) + origin_pos_y)\n",
    "            if (x_pos - origin_pos_x)**2 + (y_pos - origin_pos_y)**2 > (int(image_size/2*r))**2:\n",
    "                break\n",
    "            value_p = np.random.binomial(n=1, p=p, size=(3, 3))\n",
    "            x_index = [x_pos - 1, x_pos, x_pos+1]\n",
    "            y_index = [y_pos - 1, y_pos, y_pos+1]\n",
    "            x[np.ix_(x_index, y_index)] = value_p\n",
    "    else:\n",
    "        for y_pos in range(origin_pos_y, origin_pos_y + round(image_size/2*r*z2), sign(z2)):\n",
    "            x_pos = round(z1/z2*(y_pos - origin_pos_y) + origin_pos_x)\n",
    "            if (x_pos - origin_pos_x)**2 + (y_pos - origin_pos_y)**2 > (int(image_size/2*r))**2:\n",
    "                break\n",
    "            value_p = np.random.binomial(n=1, p=p, size=(3, 3))\n",
    "            x_index = [x_pos - 1, x_pos, x_pos+1]\n",
    "            y_index = [y_pos - 1, y_pos, y_pos+1]\n",
    "            x[np.ix_(x_index, y_index)] = value_p\n",
    "            \n",
    "    if i == 0:\n",
    "        x_data = torch.tensor(x)[None, :]\n",
    "    else:\n",
    "        x_data = torch.cat((x_data, torch.tensor(x)[None, :]), 0)\n",
    "        \n",
    "x_data = x_data.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99b2102-2257-4570-8862-697b87af5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf17e648-6877-4e8c-8a9d-896c95d13b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, label):\n",
    "        self.x = x\n",
    "        self.label = label\n",
    "        self.n = x.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a5a9519-c568-4a72-b35c-d1d27a742105",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.full((n, ), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2baf9d56-1699-4e5c-911f-5bd97cc71477",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = 8000\n",
    "train_x, train_label = x[:split_idx], label[:split_idx]\n",
    "test_x, test_label = x[split_idx:], label[split_idx:]\n",
    "train_dataset = CustomDataset(train_x, train_label)\n",
    "test_dataset = CustomDataset(test_x, test_label)\n",
    "\n",
    "import pickle\n",
    "train_file = './data/model/train_dataset.pkl'\n",
    "test_file = './data/model/test_dataset.pkl'\n",
    "\n",
    "with open(train_file, 'wb') as f:\n",
    "    pickle.dump(train_dataset, f)\n",
    "with open(test_file, 'wb') as f:\n",
    "    pickle.dump(test_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57560d06-9cd6-42ff-9e4f-ad4e9e861ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "train_file = './data/model/train_dataset.pkl'\n",
    "test_file = './data/model/test_dataset.pkl'\n",
    "\n",
    "with open(train_file, 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open(test_file, 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "bs = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea3737b0-5576-4d67-a8d9-eff97cf3c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start deleting\n",
      "done deleting\n",
      "start saving\n",
      "done saving\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "num_samples = 8000\n",
    "indices = np.random.choice(len(train_dataset), num_samples, replace=False)\n",
    "subset_train_dataset = Subset(train_dataset, indices)\n",
    "\n",
    "print(\"start deleting\")\n",
    "import shutil\n",
    "save_dir = './samples/base'\n",
    "if os.path.exists(save_dir) and os.path.isdir(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "else:\n",
    "    print(f\"Directory does not exist.\")\n",
    "print(\"done deleting\")\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(\"start saving\")\n",
    "def save_images(dataset, save_dir):\n",
    "    for idx, (image, label) in enumerate(dataset):\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        image.save(os.path.join(save_dir, f'image_{idx}.png'))\n",
    "save_images(subset_train_dataset, save_dir)\n",
    "print(\"done saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c94d1d-af23-4e0a-a3b2-f02d9068c7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
